{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 1"
      ],
      "metadata": {
        "id": "hoDgY8LQLuhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализовать класс для работы с линейной регрессией"
      ],
      "metadata": {
        "id": "dwo3ddTS-SL3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51di5NLe-Bxm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "import time\n",
        "\n",
        "class MyLinearRegression:\n",
        "    def __init__(self,\n",
        "                 regularization=None,\n",
        "                 weight_calc='matrix',\n",
        "                 lambda_1=None,\n",
        "                 lambda_2=None,\n",
        "                 batch_size=20,\n",
        "                 max_iter=1000,\n",
        "                 lr=0.001,\n",
        "                 tol=1e-6):\n",
        "\n",
        "        if regularization not in [None, 'l1', 'l2', 'l1l2']:\n",
        "            raise TypeError(f\"Параметр regularization не может принимать значение '{regularization}'\")\n",
        "        if weight_calc not in ['matrix', 'gd', 'sgd']:\n",
        "            raise TypeError(f\"Параметр weight_calc не может принимать значение '{weight_calc}'\")\n",
        "        if regularization in ['l1', 'l1l2'] and lambda_1 is None:\n",
        "            raise TypeError(\"Значение коэффициента регуляризации l1 не задано\")\n",
        "        if regularization in ['l2', 'l1l2'] and lambda_2 is None:\n",
        "            raise TypeError(\"Значение коэффициента регуляризации l2 не задано\")\n",
        "        if regularization in ['l1', 'l1l2'] and weight_calc == 'matrix':\n",
        "            raise TypeError(\"При регуляризациях L1 или L1+L2 нельзя использовать weight_calc='matrix'\")\n",
        "\n",
        "        self.regularization = regularization\n",
        "        self.weight_calc = weight_calc\n",
        "        self.lambda_1 = lambda_1\n",
        "        self.lambda_2 = lambda_2\n",
        "        self.batch_size = batch_size\n",
        "        self.max_iter = max_iter\n",
        "        self.lr = lr\n",
        "        self.tol = tol\n",
        "\n",
        "        self.coefs_ = None\n",
        "        self.intercept_ = None\n",
        "\n",
        "    def _add_intercept(self, X):\n",
        "        return np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "\n",
        "    def _loss_and_grad(self, X, y, w):\n",
        "        n = X.shape[0]\n",
        "        y_pred = X @ w\n",
        "        diff = y_pred - y.reshape(-1, 1)\n",
        "        loss = (diff ** 2).mean()\n",
        "\n",
        "        if self.regularization is not None:\n",
        "            w_reg = w[1:]\n",
        "            if self.regularization == 'l1':\n",
        "                loss += self.lambda_1 * np.sum(np.abs(w_reg))  # L1 регуляризация\n",
        "            elif self.regularization == 'l2':\n",
        "                loss += self.lambda_2 * np.sum(w_reg**2)  # L2 регуляризация\n",
        "            elif self.regularization == 'l1l2':\n",
        "                loss += self.lambda_1 * np.sum(np.abs(w_reg)) + self.lambda_2 * np.sum(w_reg**2)\n",
        "\n",
        "        grad = (2/n) * (X.T @ diff)\n",
        "\n",
        "        # Регуляризация градиента\n",
        "        if self.regularization is not None:\n",
        "            w_reg = w[1:]\n",
        "            if self.regularization in ['l2', 'l1l2']:\n",
        "                grad[1:] += 2 * self.lambda_2 * w_reg  # Регуляризация L2\n",
        "            if self.regularization in ['l1', 'l1l2']:\n",
        "                grad[1:] += self.lambda_1 * np.sign(w_reg)  # Регуляризация L1\n",
        "\n",
        "        return loss, grad\n",
        "\n",
        "    # Метод для градиентного спуска (полный)\n",
        "    def _fit_gd(self, X, y):\n",
        "        w = np.random.randn(X.shape[1], 1) * 0.01\n",
        "        prev_loss = np.inf\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            loss, grad = self._loss_and_grad(X, y, w)\n",
        "            w = w - self.lr * grad\n",
        "            if abs(prev_loss - loss) < self.tol:\n",
        "                break\n",
        "            prev_loss = loss\n",
        "        return w\n",
        "\n",
        "    # Метод для стохастического градиентного спуска\n",
        "    def _fit_sgd(self, X, y):\n",
        "        n = X.shape[0]\n",
        "        w = np.zeros((X.shape[1], 1))\n",
        "        prev_loss = np.inf\n",
        "\n",
        "        # Итерации стохастического градиентного спуска\n",
        "        for i in range(self.max_iter):\n",
        "            idx = np.random.randint(0, n, self.batch_size)\n",
        "            X_batch = X[idx]\n",
        "            y_batch = y[idx]\n",
        "            loss, grad = self._loss_and_grad(X_batch, y_batch, w)\n",
        "            w = w - self.lr * grad\n",
        "            if abs(prev_loss - loss) < self.tol:\n",
        "                break\n",
        "            prev_loss = loss\n",
        "        return w\n",
        "\n",
        "    # Метод для решения задачи с помощью матричного метода\n",
        "    def _fit_matrix(self, X, y):\n",
        "        n, p = X.shape\n",
        "        XTX = X.T @ X  # Матрица X^T * X\n",
        "        XTy = X.T @ y.reshape(-1, 1)  # Вектор X^T * y\n",
        "\n",
        "        # Решение для разных типов регуляризации\n",
        "        if self.regularization is None:\n",
        "            w = np.linalg.inv(XTX) @ XTy  # Решение без регуляризации\n",
        "        elif self.regularization == 'l2':\n",
        "            I = np.eye(p)  # Единичная матрица для регуляризации\n",
        "            I[0, 0] = 0\n",
        "            w = np.linalg.inv(XTX + self.lambda_2 * I) @ XTy  # Регуляризация L2\n",
        "        else:\n",
        "            raise ValueError(\"Неподдерживаемое сочетание для матричного решения\")\n",
        "        return w\n",
        "\n",
        "    # Основной метод для обучения модели\n",
        "    def fit(self, X: pd.DataFrame, y: pd.DataFrame):\n",
        "        X_ext = self._add_intercept(X)\n",
        "        if self.weight_calc == 'matrix':\n",
        "            w = self._fit_matrix(X_ext, y)\n",
        "        elif self.weight_calc == 'gd':\n",
        "            w = self._fit_gd(X_ext, y)\n",
        "        else:\n",
        "            w = self._fit_sgd(X_ext, y)\n",
        "\n",
        "        self.intercept_ = w[0, 0]\n",
        "        self.coefs_ = w[1:].ravel()\n",
        "        return self\n",
        "\n",
        "    # Метод для предсказания на новых данных\n",
        "    def predict(self, X: np.array):\n",
        "        X_ext = self._add_intercept(X)\n",
        "        return X_ext @ np.concatenate([[self.intercept_], self.coefs_]).reshape(-1, 1)\n",
        "\n",
        "    # Метод для оценки точности модели (R^2)\n",
        "    def score(self, X: np.array, y: np.array):\n",
        "        y_pred = self.predict(X)\n",
        "        ss_res = np.sum((y - y_pred.ravel())**2)  # Остаточная сумма квадратов\n",
        "        ss_tot = np.sum((y - y.mean())**2)  # Общая сумма квадратов\n",
        "        r2 = 1 - ss_res / ss_tot  # Рассчитываем коэффициент детерминации (R^2)\n",
        "        return r2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "# Целевой признак\n",
        "y = data['price'].values\n",
        "\n",
        "# Признаки\n",
        "X = data.drop(columns='price')\n",
        "\n",
        "# Нормализация данных\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.drop(columns=['model', 'transmission']))\n",
        "\n",
        "# Кодируем категориальные признаки\n",
        "cat_cols = ['model', 'transmission']\n",
        "enc = OneHotEncoder(sparse_output=False, drop='first')\n",
        "X_cat = enc.fit_transform(X[cat_cols])\n",
        "\n",
        "X_all = np.hstack([X_cat, X_scaled])\n",
        "\n",
        "X_train, y_train = X_all, y\n",
        "X_test, y_test = X_all, y\n",
        "\n",
        "# Сравнение различных конфигураций\n",
        "configs = [\n",
        "    (None, 'matrix', None, None),\n",
        "    ('l2', 'matrix', None, 10.0),\n",
        "    ('l2', 'gd', None, 10.0),\n",
        "    ('l1', 'gd', 1.0, None),\n",
        "    ('l1l2', 'sgd', 1.0, 10.0),\n",
        "]\n",
        "\n",
        "for regularization, weight_calc, l1, l2 in configs:\n",
        "    model = MyLinearRegression(\n",
        "        regularization=regularization,\n",
        "        weight_calc=weight_calc,\n",
        "        lambda_1=l1,\n",
        "        lambda_2=l2,\n",
        "        max_iter=100,\n",
        "        lr=0.0001\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    train_score = model.score(X_train, y_train)\n",
        "    test_score = model.score(X_test, y_test)\n",
        "    prediction_time_start = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    prediction_time = time.time() - prediction_time_start\n",
        "\n",
        "    print(f\"regularization={regularization}, weight_calc={weight_calc}, l1={l1}, l2={l2}\")\n",
        "    print(f\"Intercept: {model.intercept_}\")\n",
        "    print(f\"Train R^2: {train_score}, Test R^2: {test_score}\")\n",
        "    print(f\"Training time: {train_time:.6f}s, Prediction time: {prediction_time:.6f}s\")\n",
        "    print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23UtfHo-eOsn",
        "outputId": "a89abc87-e3c0-4bf9-b977-e93a7dc745cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "regularization=None, weight_calc=matrix, l1=None, l2=None\n",
            "Intercept: 5987.703609416494\n",
            "Train R^2: 0.8534638500411593, Test R^2: 0.8534638500411593\n",
            "Training time: 0.000245s, Prediction time: 0.000038s\n",
            "--------------------------------------------------\n",
            "regularization=l2, weight_calc=matrix, l1=None, l2=1.0\n",
            "Intercept: 5983.364089389988\n",
            "Train R^2: 0.8534018898281588, Test R^2: 0.8534018898281588\n",
            "Training time: 0.000224s, Prediction time: 0.000038s\n",
            "--------------------------------------------------\n",
            "regularization=l2, weight_calc=gd, l1=None, l2=1.0\n",
            "Intercept: 5983.239823211249\n",
            "Train R^2: 0.8533677843956781, Test R^2: 0.8533677843956781\n",
            "Training time: 0.005685s, Prediction time: 0.000039s\n",
            "--------------------------------------------------\n",
            "regularization=l1, weight_calc=gd, l1=0.1, l2=None\n",
            "Intercept: 5983.512307128194\n",
            "Train R^2: 0.8533592278362112, Test R^2: 0.8533592278362112\n",
            "Training time: 0.006075s, Prediction time: 0.000040s\n",
            "--------------------------------------------------\n",
            "regularization=l1l2, weight_calc=sgd, l1=0.1, l2=1.0\n",
            "Intercept: 5982.904012654874\n",
            "Train R^2: 0.8533499022768425, Test R^2: 0.8533499022768425\n",
            "Training time: 0.009623s, Prediction time: 0.000054s\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используя датасет про автомобили (целевой признак — price), сравнить (качество, скорость обучения и предсказания, важность признаков) модели `MyLinearRegression` с различными гиперпараметрами, сделать выводы."
      ],
      "metadata": {
        "id": "flYIBMseNV2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Время обучения и предсказания незначительно влияет на качество модели, которое везде остаётся на уровне около 0.853 (практически идентично). Это указывает на то, что изменения гиперпараметров, связанные с регуляризацией и методами расчёта весов, не оказывают значительного влияния на точность предсказания.\n",
        "\n",
        "Модели с регуляризацией L2 и L1 имеют схожие значения по времени, но использование комбинированной регуляризации (L1L2) увеличивает время обучения и предсказания, что может быть связано с дополнительной сложностью модели.\n",
        "\n",
        "Включение регуляризации (L1 или L2) в целом не ведёт к значительному ухудшению качества модели. Однако, комбинация L1 и L2 регуляризаций немного снижает R² и увеличивает время работы модели, что нужно учитывать при выборе гиперпараметров в реальных приложениях.\n",
        "\n",
        "Таким образом, для данной задачи можно рекомендовать использование модели с L2 регуляризацией без значительного увеличения времени работы, если дополнительная сложность, связанная с L1 или комбинированной регуляризацией, не приносит значимого улучшения в результатах."
      ],
      "metadata": {
        "id": "D7XAfFq5gVlm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задача 2\n",
        "\n",
        "[Соревнование на Kaggle](https://www.kaggle.com/competitions/stat-plus-ml-2024)"
      ],
      "metadata": {
        "id": "jKO_QAb5Lmdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Загрузка данных\n",
        "train_data = pd.read_csv('train_contest.csv')\n",
        "test_data = pd.read_csv('for_prediction.csv')\n",
        "\n",
        "train_data['area'] = train_data['area'].apply(lambda x: eval(x)['name'] if isinstance(eval(x), dict) else x)\n",
        "test_data['area'] = test_data['area'].apply(lambda x: eval(x)['name'] if isinstance(eval(x), dict) else x)\n",
        "\n",
        "train_data['experience'] = train_data['experience'].apply(lambda x: eval(x)['name'] if isinstance(eval(x), dict) else x)\n",
        "test_data['experience'] = test_data['experience'].apply(lambda x: eval(x)['name'] if isinstance(eval(x), dict) else x)\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('area', OneHotEncoder(handle_unknown='ignore'), ['area']),\n",
        "        ('experience', OneHotEncoder(handle_unknown='ignore'), ['experience']),\n",
        "        ('premium', SimpleImputer(strategy='mean'), ['premium'])\n",
        "    ])\n",
        "\n",
        "# Признаки для обучения\n",
        "X = train_data[['area', 'premium', 'experience']]\n",
        "y = train_data['mean_salary']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Прогнозирование на тестовых данных\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка модели (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "\n",
        "# Прогнозирование на новых данных\n",
        "X_new = test_data[['area', 'premium', 'experience']]  # Используем те же признаки для тестовых данных\n",
        "y_new_pred = model.predict(X_new)\n",
        "\n",
        "# Формирование DataFrame с результатами для отправки\n",
        "submission = pd.DataFrame({'Id': test_data['Id'], 'Predicted': y_new_pred})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Прогнозы сохранены в 'submission.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK94uyWPkNe9",
        "outputId": "7464be17-2710-49a6-fe6d-34c8eb8483d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 50003.02719272275\n",
            "Прогнозы сохранены в 'submission.csv'\n"
          ]
        }
      ]
    }
  ]
}