{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 1"
      ],
      "metadata": {
        "id": "vDjH5VgLMPCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пусть $X_1, X_2, \\ldots, X_n$ — выборка из экспоненциального распределения с параметром $\\lambda$. Найти оценку максимального правдоподобия параметра $\\lambda$, сравнить ее с байесовской оценкой (MAP и математическое ожидание апостреорного распределения), подобрав сопряженное распределение. Сравнить полученные байесовские оценки с оценкой MLE. Найти предсказательное распределение"
      ],
      "metadata": {
        "id": "y8T7M9eQMRRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пусть $X_1, X_2, \\dots, X_n$ — выборка из экспоненциального распределения с параметром $\\lambda$. Необходимо найти:\n",
        "\n",
        "1. Оценку максимального правдоподобия (MLE) для параметра $\\lambda$.\n",
        "2. Байесовскую оценку (MAP и математическое ожидание апостериорного распределения).\n",
        "3. Сравнить полученные байесовские оценки с оценкой MLE.\n",
        "4. Найти предсказательное распределение.\n",
        "\n",
        "Экспоненциальное распределение с параметром $\\lambda$ имеет плотность вероятности:\n",
        "\n",
        "$$\n",
        "f(x \\mid \\lambda) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0, \\lambda > 0.\n",
        "$$\n",
        "\n",
        "### Оценка максимального правдоподобия (MLE)\n",
        "\n",
        "Для оценки максимального правдоподобия параметра $\\lambda$ сначала запишем функцию правдоподобия для выборки $X_1, X_2, \\dots, X_n$.\n",
        "\n",
        "#### 1. Функция правдоподобия\n",
        "\n",
        "Функция правдоподобия для $n$ независимых наблюдений из экспоненциального распределения:\n",
        "\n",
        "$$\n",
        "L(\\lambda) = \\prod_{i=1}^{n} f(X_i \\mid \\lambda) = \\prod_{i=1}^{n} \\lambda e^{-\\lambda X_i}.\n",
        "$$\n",
        "\n",
        "Это можно переписать как:\n",
        "\n",
        "$$\n",
        "L(\\lambda) = \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} X_i}.\n",
        "$$\n",
        "\n",
        "#### 2. Логарифм функции правдоподобия\n",
        "\n",
        "Для упрощения вычислений возьмем логарифм функции правдоподобия:\n",
        "\n",
        "$$\n",
        "\\ell(\\lambda) = \\log L(\\lambda) = n \\log \\lambda - \\lambda \\sum_{i=1}^{n} X_i.\n",
        "$$\n",
        "\n",
        "#### 3. Производная логарифма функции правдоподобия\n",
        "\n",
        "Для нахождения оценки максимального правдоподобия максимизируем логарифм функции правдоподобия по $\\lambda$. Для этого вычислим первую производную:\n",
        "\n",
        "$$\n",
        "\\frac{d}{d\\lambda} \\ell(\\lambda) = \\frac{n}{\\lambda} - \\sum_{i=1}^{n} X_i.\n",
        "$$\n",
        "\n",
        "#### 4. Находим максимальную точку\n",
        "\n",
        "Приравняем производную к нулю, чтобы найти точку максимума:\n",
        "\n",
        "$$\n",
        "\\frac{n}{\\lambda} = \\sum_{i=1}^{n} X_i,\n",
        "$$\n",
        "\n",
        "откуда\n",
        "\n",
        "$$\n",
        "\\hat{\\lambda}_{\\text{MLE}} = \\frac{n}{\\sum_{i=1}^{n} X_i}.\n",
        "$$\n",
        "\n",
        "Таким образом, оценка максимального правдоподобия для $\\lambda$ равна обратной величине среднего значения выборки.\n",
        "\n",
        "### Байесовская оценка\n",
        "\n",
        "Для байесовской оценки будем использовать сопряженное распределение для параметра $\\lambda$. Сопряжённым распределением для параметра $\\lambda$ в экспоненциальном распределении является гамма-распределение.\n",
        "\n",
        "#### 1. Сопряженное распределение\n",
        "\n",
        "Предположим, что априорное распределение для $\\lambda$ имеет гамма-распределение с параметрами $\\alpha$ и $\\beta$:\n",
        "\n",
        "$$\n",
        "p(\\lambda) = \\frac{\\beta^\\alpha \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}}{\\Gamma(\\alpha)}, \\quad \\lambda > 0.\n",
        "$$\n",
        "\n",
        "#### 2. Апостериорное распределение\n",
        "\n",
        "Согласно байесовскому методу, апостериорное распределение пропорционально произведению функции правдоподобия и априорного распределения:\n",
        "\n",
        "$$\n",
        "p(\\lambda \\mid X_1, X_2, \\dots, X_n) \\propto L(\\lambda) p(\\lambda).\n",
        "$$\n",
        "\n",
        "Подставляем функции правдоподобия и априорного распределения:\n",
        "\n",
        "$$\n",
        "p(\\lambda \\mid X_1, X_2, \\dots, X_n) \\propto \\lambda^n e^{-\\lambda \\sum_{i=1}^{n} X_i} \\cdot \\lambda^{\\alpha - 1} e^{-\\beta \\lambda}.\n",
        "$$\n",
        "\n",
        "Упростим выражение:\n",
        "\n",
        "$$\n",
        "p(\\lambda \\mid X_1, X_2, \\dots, X_n) \\propto \\lambda^{n + \\alpha - 1} e^{-\\lambda \\left( \\beta + \\sum_{i=1}^{n} X_i \\right)}.\n",
        "$$\n",
        "\n",
        "Это снова гамма-распределение с параметрами $\\alpha' = \\alpha + n$ и $\\beta' = \\beta + \\sum_{i=1}^{n} X_i$:\n",
        "\n",
        "$$\n",
        "p(\\lambda \\mid X_1, X_2, \\dots, X_n) = \\frac{(\\beta + \\sum_{i=1}^{n} X_i)^{\\alpha + n - 1} \\lambda^{\\alpha + n - 1} e^{-(\\beta + \\sum_{i=1}^{n} X_i) \\lambda}}{\\Gamma(\\alpha + n)}.\n",
        "$$\n",
        "\n",
        "#### 3. Оценка MAP\n",
        "\n",
        "Оценка MAP (Maximum A Posteriori) — это значение $\\lambda$, которое максимизирует апостериорное распределение. Максимум гамма-распределения находится в точке:\n",
        "\n",
        "$$\n",
        "\\hat{\\lambda}_{\\text{MAP}} = \\frac{\\alpha + n}{\\beta + \\sum_{i=1}^{n} X_i}.\n",
        "$$\n",
        "\n",
        "#### 4. Математическое ожидание апостериорного распределения\n",
        "\n",
        "Математическое ожидание для гамма-распределения с параметрами $\\alpha'$ и $\\beta'$ равно:\n",
        "\n",
        "$$\n",
        "\\mathbb{E}[\\lambda \\mid X_1, X_2, \\dots, X_n] = \\frac{\\alpha + n}{\\beta + \\sum_{i=1}^{n} X_i}.\n",
        "$$\n",
        "\n",
        "Это также будет являться байесовской оценкой для $\\lambda$.\n",
        "\n",
        "### Сравнение оценок\n",
        "\n",
        "1. **Оценка MLE**:\n",
        "\n",
        "   $$\n",
        "   \\hat{\\lambda}_{\\text{MLE}} = \\frac{n}{\\sum_{i=1}^{n} X_i}.\n",
        "   $$\n",
        "\n",
        "2. **Оценка MAP и математическое ожидание апостериорного распределения**:\n",
        "\n",
        "   $$\n",
        "   \\hat{\\lambda}_{\\text{MAP}} = \\mathbb{E}[\\lambda \\mid X_1, X_2, \\dots, X_n] = \\frac{\\alpha + n}{\\beta + \\sum_{i=1}^{n} X_i}.\n",
        "   $$\n",
        "\n",
        "Как видно, оценка MAP и математическое ожидание апостериорного распределения зависит от априорных параметров $\\alpha$ и $\\beta$. Когда априорная информация отсутствует (то есть $\\alpha$ и $\\beta$ малы), оценка MAP приближается к оценке MLE.\n",
        "\n",
        "### Предсказательное распределение\n",
        "\n",
        "Предсказательное распределение для следующего наблюдения $X_{n+1}$ при условии данных $X_1, X_2, \\dots, X_n$ можно получить интегрированием по апостериорному распределению для $\\lambda$:\n",
        "\n",
        "$$\n",
        "p(X_{n+1} \\mid X_1, X_2, \\dots, X_n) = \\int_0^\\infty p(X_{n+1} \\mid \\lambda) p(\\lambda \\mid X_1, X_2, \\dots, X_n) d\\lambda.\n",
        "$$\n",
        "\n",
        "Здесь $p(X_{n+1} \\mid \\lambda) = \\lambda e^{-\\lambda X_{n+1}}$ — это вероятность для следующего наблюдения при фиксированном $\\lambda$, а $p(\\lambda \\mid X_1, X_2, \\dots, X_n)$ — это апостериорное распределение для $\\lambda$.\n",
        "\n",
        "Подставив форму апостериорного распределения, получаем предсказательное распределение:\n",
        "\n",
        "$$\n",
        "p(X_{n+1} \\mid X_1, X_2, \\dots, X_n) = \\frac{(\\beta + \\sum_{i=1}^{n} X_i)^{\\alpha + n}}{(\\beta + \\sum_{i=1}^{n} X_i)^{\\alpha + n + 1}} \\Gamma(\\alpha + n).\n",
        "$$"
      ],
      "metadata": {
        "id": "ta-G9jh335lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 2"
      ],
      "metadata": {
        "id": "5WBXJuchMhzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Мультиномиальное распределение**\n",
        "\n",
        "Пусть проводится серия из $n$ испытаний и в результате каждого испытания происходит ровно одно событие из набора $A_1, A_2, \\dots, A_m$, причем вероятности этих событий равны соответственно $\\mathsf{p}_1, \\mathsf{p}_2, \\dots, \\mathsf{p}_m$, причем\n",
        "$$\\sum_{i=1}^{m}\\mathsf{p}_i = 1.$$\n",
        "\n",
        "Тогда совместное распределение величин $X_1, X_2, \\dots, X_m$, где $X_k$ — число наступлений события $A_k$ в серии из $n$ испытаний, задается вероятностями\n",
        "\n",
        "$$\n",
        "\\mathsf{P}\\left(X_1 = n_1, \\dots, X_m = n_m, \\right) = \\frac{n!}{n_1!\\dots n_m!}\\mathsf{p}_1^{n_1}\\dots \\mathsf{p}_m^{n_m},\n",
        "$$\n",
        "\n",
        "где $n_1, n_2, \\dots, n_m$ — произвольный набор целых неотрицательных чисел, таких что\n",
        "\n",
        "$$\\sum_{i=1}^m n_i = n.$$"
      ],
      "metadata": {
        "id": "uYWArd6bMjkD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Произведите байесовский вывод для мультиномиального распределения: найдите апостериорное распределение, используя в качестве сопоряженного распределения к правдоподобию [распределение Дирихле](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%94%D0%B8%D1%80%D0%B8%D1%85%D0%BB%D0%B5), найдите предсказательное распределение. Объясните результат."
      ],
      "metadata": {
        "id": "yOvNMoSHMrWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Байесовский вывод\n",
        "\n",
        "Для байесовского вывода нам нужно вычислить апостериорное распределение для вероятностей $\\mathsf{p}_1, \\mathsf{p}_2, \\dots, \\mathsf{p}_m$, условно на наблюдаемые данные $n_1, n_2, \\dots, n_m$.\n",
        "\n",
        "Функция правдоподобия для мультиномиального распределения выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "L(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid n_1, \\dots, n_m) = \\frac{n!}{n_1! \\dots n_m!} \\mathsf{p}_1^{n_1} \\dots \\mathsf{p}_m^{n_m},\n",
        "$$\n",
        "\n",
        "где $\\mathsf{p}_1, \\dots, \\mathsf{p}_m$ — вероятности для событий $A_1, A_2, \\dots, A_m$.\n",
        "\n",
        "Используем в качестве априорного распределения **распределение Дирихле**, которое является сопряженным распределением для мультиномиального распределения. Распределение Дирихле имеет вид:\n",
        "\n",
        "$$\n",
        "p(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid \\alpha_1, \\dots, \\alpha_m) = \\frac{1}{B(\\alpha_1, \\dots, \\alpha_m)} \\prod_{i=1}^{m} \\mathsf{p}_i^{\\alpha_i - 1},\n",
        "$$\n",
        "\n",
        "где $\\alpha_1, \\dots, \\alpha_m$ — параметры (гиперпараметры) распределения, а $B(\\alpha_1, \\dots, \\alpha_m)$ — бета-функция многомерного типа, которая нормирует распределение.\n",
        "\n",
        "Согласно байесовской теореме, апостериорное распределение пропорционально произведению функции правдоподобия и априорного распределения:\n",
        "\n",
        "$$\n",
        "p(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid n_1, \\dots, n_m, \\alpha_1, \\dots, \\alpha_m) \\propto L(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid n_1, \\dots, n_m) \\cdot p(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid \\alpha_1, \\dots, \\alpha_m).\n",
        "$$\n",
        "\n",
        "Подставляем правдоподобие и априорное распределение:\n",
        "\n",
        "$$\n",
        "p(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid n_1, \\dots, n_m, \\alpha_1, \\dots, \\alpha_m) \\propto \\left( \\prod_{i=1}^{m} \\mathsf{p}_i^{n_i} \\right) \\cdot \\left( \\prod_{i=1}^{m} \\mathsf{p}_i^{\\alpha_i - 1} \\right).\n",
        "$$\n",
        "\n",
        "Упростим выражение:\n",
        "\n",
        "$$\n",
        "p(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid n_1, \\dots, n_m, \\alpha_1, \\dots, \\alpha_m) \\propto \\prod_{i=1}^{m} \\mathsf{p}_i^{n_i + \\alpha_i - 1}.\n",
        "$$\n",
        "\n",
        "Это также распределение Дирихле с параметрами:\n",
        "\n",
        "$$\n",
        "\\alpha_i' = \\alpha_i + n_i.\n",
        "$$\n",
        "\n",
        "Таким образом, апостериорное распределение для $\\mathsf{p}_1, \\dots, \\mathsf{p}_m$ также будет распределением Дирихле с параметрами $\\alpha_1' = \\alpha_1 + n_1, \\dots, \\alpha_m' = \\alpha_m + n_m$.\n",
        "\n",
        "---\n",
        "\n",
        "#### Предсказательное распределение\n",
        "\n",
        "Предсказательное распределение для следующего наблюдения в серии испытаний можно получить путем интегрирования апостериорного распределения по вероятностям $\\mathsf{p}_1, \\dots, \\mathsf{p}_m$. Предсказательное распределение для количества наступлений события $A_k$ в следующем испытании будет:\n",
        "\n",
        "$$\n",
        "\\mathsf{P}(X_{n+1} = n_{k+1}) = \\int_0^1 \\dots \\int_0^1 \\mathsf{p}_k^{n_{k+1}} p(\\mathsf{p}_1, \\dots, \\mathsf{p}_m \\mid n_1, \\dots, n_m, \\alpha_1, \\dots, \\alpha_m) d\\mathsf{p}_1 \\dots d\\mathsf{p}_m.\n",
        "$$\n",
        "\n",
        "Используя апостериорное распределение, получаем следующее распределение для количества наступлений $X_{n+1}$:\n",
        "\n",
        "$$\n",
        "\\mathsf{P}(X_{n+1} = n_{k+1}) = \\frac{\\alpha_k + n_k}{\\sum_{i=1}^m (\\alpha_i + n_i)}.\n",
        "$$\n",
        "\n",
        "Это распределение является **распределением Бета-Биномиальным** и представляет собой вероятность того, что в следующем испытании произойдет событие $A_k$, с учетом предыдущих наблюдений и априорной информации.\n",
        "\n",
        "---\n",
        "\n",
        "#### Результаты\n",
        "\n",
        "- **Апостериорное распределение**: Это распределение дает нам обновленную информацию о вероятностях событий после наблюдения данных. Параметры распределения Дирихле для апостериорного распределения $\\mathsf{p}_1, \\dots, \\mathsf{p}_m$ изменяются на величину количества наступлений каждого события в предыдущих испытаниях.\n",
        "  \n",
        "- **Предсказательное распределение**: Предсказательное распределение позволяет предсказать вероятности для следующих наблюдений, с учетом предыдущих данных и априорных распределений. Оно выводится как бета-биномиальное распределение и предоставляет нам обновленную оценку для вероятностей наступления различных событий в будущем.\n",
        "\n",
        "Таким образом, байесовский подход позволяет учитывать как априорную информацию, так и данные, что делает его более гибким инструментом для прогнозирования по сравнению с классическими методами.\n"
      ],
      "metadata": {
        "id": "AMDaTK-o4NSA"
      }
    }
  ]
}